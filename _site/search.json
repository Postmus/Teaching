[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistics labs",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites.\n\n1 + 1\n\n[1] 2\n\n\ndsdsdfs"
  },
  {
    "objectID": "Beyond MLR/BLR_lab2.html",
    "href": "Beyond MLR/BLR_lab2.html",
    "title": "Beyond Linear Regression Lab 2: Random Effects Model for the One-Way Layout",
    "section": "",
    "text": "Consider an observational study in which waist circumference measurements (in centimeters) are taken by multiple nurses. These nurses may have varying measurement techniques, levels of experience, or adherence to standardized protocols, leading to variability in recorded waist circumference measurements. Our aim is to assess the extent of variability in waist circumference measurements attributed to differences among nurses.\nTo facilitate our analysis, we will simulate a dataset where waist circumference measurements are recorded by four different nurses.\n\n# Setting seed for reproducibility\nset.seed(789)\n\n# Number of nurses and measurements per nurse\nnum_nurses &lt;- 4\nmeasurements_per_nurse &lt;- 50\n\n# Simulating nurse effects (random effects)\nnurse_effects &lt;- rnorm(num_nurses, mean = 0, sd = 1.5)  # Nurse-specific deviations\n\n# Simulating residual errors\nresidual_errors &lt;- rnorm(num_nurses * measurements_per_nurse, mean = 0, sd = 3)\n\n# Simulating Waist Circumference Measurements\nWaist_Circumference &lt;- 80 + rep(nurse_effects, each = measurements_per_nurse) + residual_errors\n\n# Creating Nurse factor\nNurse &lt;- factor(rep(paste(\"Nurse\", LETTERS[1:num_nurses]), each = measurements_per_nurse))\n\n# Combining into a data frame\ndata_waist_circumference &lt;- data.frame(\n  Nurse = Nurse,\n  Waist_Circumference = Waist_Circumference\n)\n\nThe above R chunk simulates 200 hypothetical waist circumference measurements for four different nurses (50 measurements per nurse) and stores the results in the data frame data_waist_circumference that consists of the following two columns:\n\nNurse: Factor variable indicating the nurse who performed the measurement (Nurse A, Nurse B, Nurse C, Nurse D).\nWaist_Circumference: Numeric variable representing the waist circumference measurement (in centimeters).\n\n\n\nBefore modeling, it’s important to visualize and summarize the data to identify any trends, patterns, or anomalies that may impact the analysis. In this case, we aim to explore the variability in waist circumference measurements across nurses and assess the consistency of these measurements.\nWe’ll use two main approaches:\n\nVisualizing the data: A boxplot will be created to compare waist circumference measurements across nurses, highlighting differences in measurement tendencies or variability.\nSummarizing the data: Summary statistics (mean and standard deviation) will be computed for each nurse, providing a numerical overview of central tendency and spread for the measurements.\n\n\n# Create a boxplot\nlibrary(ggplot2)\nggplot(data_waist_circumference, aes(x = Nurse, y = Waist_Circumference, fill = Nurse)) +\n  geom_boxplot() +\n  labs(title = \"Waist Circumference Measurements by Nurse\",\n       x = \"Nurse\", y = \"Waist Circumference (cm)\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n# Calculate summary statistics\nlibrary(dplyr)\nsummary_stats_random &lt;- data_waist_circumference %&gt;%\n  group_by(Nurse) %&gt;%\n  summarise(\n    Mean_Waist = mean(Waist_Circumference),\n    SD_Waist = sd(Waist_Circumference)\n  )\n\nsummary_stats_random\n\n# A tibble: 4 × 3\n  Nurse   Mean_Waist SD_Waist\n  &lt;fct&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 Nurse A       80.4     2.69\n2 Nurse B       76.9     3.01\n3 Nurse C       79.9     3.15\n4 Nurse D       79.7     3.56\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nBased on the boxplot and summary statistics, do you observe any systematic differences in waist circumference measurements across the nurses? If so, describe the differences and what they might suggest about the measurements.\n\n\n\n\n\nA random effects model represents variations assumed to arise from a larger population. Unlike fixed effects, which estimate specific differences between levels of a factor, random effects account for variability among factor levels by treating them as random samples from a broader population.\nIn the waist circumference example, the four nurses can be considered a random sample from a larger population of nurses. By modeling “Nurse” as a random effect, we aim to generalize the findings about measurement variability to the broader population of nurses, rather than focusing solely on the four in the study.\n\n\nThe random effects model can be specified as:\n\\[\nY_{ij} = \\mu + b_i + \\epsilon_{ij}\n\\]\nwhere:\n\n\\(Y_{ij}\\): The waist circumference measurement for the \\(j\\)-th observation by the \\(i\\)-th nurse.\n\\(\\mu\\): The overall mean waist circumference.\n\\(b_i\\): The random effect of the \\(i\\)-th nurse, assumed to be normally distributed with mean zero and variance \\(\\sigma^2_{b}\\).\n\\(\\epsilon_{ij}\\): The error term, assumed to be independently and normally distributed with mean zero and variance \\(\\sigma^2\\).\n\nThe use of random effects allows us to decompose the total variance in the outcome variable into distinct components, each associated with a different source of variation. In this example, the total variance in waist circumference measurements is split into two variance components:\n\nBetween-nurse variability (\\(\\sigma^2_{b}\\)): This component, represented by the variance of the random effect \\(b_{i}\\), captures the variability in waist circumference measurements attributable to differences among nurses. It reflects how much of the overall variability is due to systematic differences in measurement techniques or practices between nurses.\nResidual variance (\\(\\sigma^2\\)): This component, represented by the variance of the error term \\(\\epsilon_{ij}\\), captures the variability in waist circumference measurements that remains unexplained by nurse-related differences. It includes measurement error, patient-specific factors, and other unmeasured sources of variation.\n\n\n\n\n\n\n\nNotation convention\n\n\n\nIn mixed-effects models, fixed effects are typically represented by Greek letters, while random effects are represented by Roman letters. This helps differentiate between the two types of effects in model specification.\n\n\n\n\nThe Intraclass Correlation Coefficient (ICC) is a statistical measure that quantifies the proportion of the total variance in the outcome variable that can be attributed to differences between groups. In this context, the ICC measures the extent to which waist circumference measurements are more similar when taken by the same nurse (within-group), compared to the overall variability across all nurses (between-group). In other words, it tells us how strongly measurements are correlated within the same group.\nMathematically, the ICC is calculated as:\n\\[\nICC = \\frac{\\sigma^2_{b}}{\\sigma^2_{b} + \\sigma^2}\n\\]\nInterpretation of ICC:\n\nICC \\(\\approx\\) 0: Indicates that nearly all the variability in waist circumference measurements is due to residual factors (such as patient differences or measurement error). This suggests that nurse-level differences contribute minimally to the total variability, implying a high degree of consistency across nurses in their measurement practices.\nICC \\(\\approx\\) 1: Indicates that nearly all the variability is attributable to differences between nurses. This suggests substantial between-nurse variability, meaning different nurses consistently record different waist circumference measurements.\n\n\n\n\n\nWe will fit the random effects model using the lmer() function from the lme4 package.\n\n# Fitting the random effects model\nlibrary(lme4)\nmodel_random &lt;- lmer(Waist_Circumference ~ 1 + (1 | Nurse), data = data_waist_circumference)\nsummary(model_random)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: Waist_Circumference ~ 1 + (1 | Nurse)\n   Data: data_waist_circumference\n\nREML criterion at convergence: 1030.5\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-2.83380 -0.59987  0.00698  0.66169  2.96673 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n Nurse    (Intercept) 2.358    1.536   \n Residual             9.730    3.119   \nNumber of obs: 200, groups:  Nurse, 4\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)  79.2094     0.7989   99.15\n\n\n\n\nLet’s break down the model formula Waist_Circumference ~ 1 + (1 | Nurse)\n\nWaist_Circumference ~ 1: This specifies that Waist_Circumference is the outcome variable and that the fixed effects structure consists of a single intercept, modeled by the term 1, that represents the overall mean waist circumference across all nurses.\n(1 | Nurse): This specifies the random effect for Nurse, representing nurse-specific deviations from the overall mean.\n\n\n\n\nWhen you run summary(model_random), the output will display:\n\nFixed Effects: Estimates of the fixed effects\n\nIntercept: The overall mean waist circumference across all nurses.\n\nRandom Effects: Estimates of the two variance components\n\nNurse - Intercept: Between-nurse variability (\\(\\sigma^2_{b}\\)).\nResidual: Residual variance (\\(\\sigma^2\\)).\n\n\n\n\n\n\n\n\nNo p-values\n\n\n\nThe lme4 package does not provide p-values for fixed effect estimates. This is a deliberate choice by the package authors, based on concerns about the appropriateness of traditional hypothesis testing methods in the context of mixed effects models. In subsequent labs, we will use of the lmerTest package to calculate these p-values and add them to the summary output.\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nWhat proportion of the total variance is attributable to nurse differences (i.e., what is the value of the ICC)?\n\n\n\n\n\nIn mixed-effects models, model diagnostics involve analyzing different types of residuals to evaluate how well the model fits the data and to assess whether key assumptions are satisfied.\nThe default type of residuals used in these models are the conditional residuals, which are calculated based on predicted values that incorporate both fixed effects and estimated random effects. Conditional residuals represent the deviation of the observed data from the model’s predictions, accounting for variability from both sources: fixed effects and random effects. They can be considered estimates of the errors \\(\\epsilon_{ij}\\), which are assumed to be normally distributed with a mean of zero and constant variance.\nTo check these assumptions, we can generate diagnostic plots similar to those used in linear regression models:\n\nResiduals vs. Fitted Plot: This plot helps check for homoscedasticity (constant variance).\nNormal Q-Q Plot: This plot assesses whether the residuals follow a normal distribution.\n\n\n# Extract conditional residuals and predicted values\nresiduals_model_random &lt;- resid(model_random)\nfitted_model_random &lt;- fitted(model_random)\n\n# Residuals vs Fitted\nggplot(data.frame(Fitted = fitted_model_random, Residuals = residuals_model_random), aes(x = Fitted, y = Residuals)) +\n  geom_point() +\n  geom_hline(yintercept = 0, linetype = \"dashed\") +\n  labs(title = \"Residuals vs Fitted\",\n       x = \"Fitted Values\", y = \"Residuals\") +\n  theme_minimal()\n\n\n\n# Normal Q-Q\nqqnorm(residuals_model_random, main = \"Normal Q-Q\")\nqqline(residuals_model_random)\n\n\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nDo the diagnostic plots suggest any violations of the model assumptions regarding the error term?\n\n\n\n\n\n\n\nA random effects model was fitted to assess the variability in waist circumference measurements across nurses. The overall mean waist circumference was estimated at 79.21 cm. The variance due to differences among nurses was 2.36 cm² and the residual variance was 9.73 cm², resulting in an Intraclass Correlation Coefficient (ICC) of 0.195."
  },
  {
    "objectID": "Beyond MLR/BLR_lab2.html#exploratory-data-analysis",
    "href": "Beyond MLR/BLR_lab2.html#exploratory-data-analysis",
    "title": "Beyond Linear Regression Lab 2: Random Effects Model for the One-Way Layout",
    "section": "",
    "text": "Before modeling, it’s important to visualize and summarize the data to identify any trends, patterns, or anomalies that may impact the analysis. In this case, we aim to explore the variability in waist circumference measurements across nurses and assess the consistency of these measurements.\nWe’ll use two main approaches:\n\nVisualizing the data: A boxplot will be created to compare waist circumference measurements across nurses, highlighting differences in measurement tendencies or variability.\nSummarizing the data: Summary statistics (mean and standard deviation) will be computed for each nurse, providing a numerical overview of central tendency and spread for the measurements.\n\n\n# Create a boxplot\nlibrary(ggplot2)\nggplot(data_waist_circumference, aes(x = Nurse, y = Waist_Circumference, fill = Nurse)) +\n  geom_boxplot() +\n  labs(title = \"Waist Circumference Measurements by Nurse\",\n       x = \"Nurse\", y = \"Waist Circumference (cm)\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n# Calculate summary statistics\nlibrary(dplyr)\nsummary_stats_random &lt;- data_waist_circumference %&gt;%\n  group_by(Nurse) %&gt;%\n  summarise(\n    Mean_Waist = mean(Waist_Circumference),\n    SD_Waist = sd(Waist_Circumference)\n  )\n\nsummary_stats_random\n\n# A tibble: 4 × 3\n  Nurse   Mean_Waist SD_Waist\n  &lt;fct&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 Nurse A       80.4     2.69\n2 Nurse B       76.9     3.01\n3 Nurse C       79.9     3.15\n4 Nurse D       79.7     3.56\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nBased on the boxplot and summary statistics, do you observe any systematic differences in waist circumference measurements across the nurses? If so, describe the differences and what they might suggest about the measurements."
  },
  {
    "objectID": "Beyond MLR/BLR_lab2.html#random-effects-model-for-the-one-way-layout",
    "href": "Beyond MLR/BLR_lab2.html#random-effects-model-for-the-one-way-layout",
    "title": "Beyond Linear Regression Lab 2: Random Effects Model for the One-Way Layout",
    "section": "",
    "text": "A random effects model represents variations assumed to arise from a larger population. Unlike fixed effects, which estimate specific differences between levels of a factor, random effects account for variability among factor levels by treating them as random samples from a broader population.\nIn the waist circumference example, the four nurses can be considered a random sample from a larger population of nurses. By modeling “Nurse” as a random effect, we aim to generalize the findings about measurement variability to the broader population of nurses, rather than focusing solely on the four in the study.\n\n\nThe random effects model can be specified as:\n\\[\nY_{ij} = \\mu + b_i + \\epsilon_{ij}\n\\]\nwhere:\n\n\\(Y_{ij}\\): The waist circumference measurement for the \\(j\\)-th observation by the \\(i\\)-th nurse.\n\\(\\mu\\): The overall mean waist circumference.\n\\(b_i\\): The random effect of the \\(i\\)-th nurse, assumed to be normally distributed with mean zero and variance \\(\\sigma^2_{b}\\).\n\\(\\epsilon_{ij}\\): The error term, assumed to be independently and normally distributed with mean zero and variance \\(\\sigma^2\\).\n\nThe use of random effects allows us to decompose the total variance in the outcome variable into distinct components, each associated with a different source of variation. In this example, the total variance in waist circumference measurements is split into two variance components:\n\nBetween-nurse variability (\\(\\sigma^2_{b}\\)): This component, represented by the variance of the random effect \\(b_{i}\\), captures the variability in waist circumference measurements attributable to differences among nurses. It reflects how much of the overall variability is due to systematic differences in measurement techniques or practices between nurses.\nResidual variance (\\(\\sigma^2\\)): This component, represented by the variance of the error term \\(\\epsilon_{ij}\\), captures the variability in waist circumference measurements that remains unexplained by nurse-related differences. It includes measurement error, patient-specific factors, and other unmeasured sources of variation.\n\n\n\n\n\n\n\nNotation convention\n\n\n\nIn mixed-effects models, fixed effects are typically represented by Greek letters, while random effects are represented by Roman letters. This helps differentiate between the two types of effects in model specification.\n\n\n\n\nThe Intraclass Correlation Coefficient (ICC) is a statistical measure that quantifies the proportion of the total variance in the outcome variable that can be attributed to differences between groups. In this context, the ICC measures the extent to which waist circumference measurements are more similar when taken by the same nurse (within-group), compared to the overall variability across all nurses (between-group). In other words, it tells us how strongly measurements are correlated within the same group.\nMathematically, the ICC is calculated as:\n\\[\nICC = \\frac{\\sigma^2_{b}}{\\sigma^2_{b} + \\sigma^2}\n\\]\nInterpretation of ICC:\n\nICC \\(\\approx\\) 0: Indicates that nearly all the variability in waist circumference measurements is due to residual factors (such as patient differences or measurement error). This suggests that nurse-level differences contribute minimally to the total variability, implying a high degree of consistency across nurses in their measurement practices.\nICC \\(\\approx\\) 1: Indicates that nearly all the variability is attributable to differences between nurses. This suggests substantial between-nurse variability, meaning different nurses consistently record different waist circumference measurements.\n\n\n\n\n\nWe will fit the random effects model using the lmer() function from the lme4 package.\n\n# Fitting the random effects model\nlibrary(lme4)\nmodel_random &lt;- lmer(Waist_Circumference ~ 1 + (1 | Nurse), data = data_waist_circumference)\nsummary(model_random)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: Waist_Circumference ~ 1 + (1 | Nurse)\n   Data: data_waist_circumference\n\nREML criterion at convergence: 1030.5\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-2.83380 -0.59987  0.00698  0.66169  2.96673 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n Nurse    (Intercept) 2.358    1.536   \n Residual             9.730    3.119   \nNumber of obs: 200, groups:  Nurse, 4\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)  79.2094     0.7989   99.15\n\n\n\n\nLet’s break down the model formula Waist_Circumference ~ 1 + (1 | Nurse)\n\nWaist_Circumference ~ 1: This specifies that Waist_Circumference is the outcome variable and that the fixed effects structure consists of a single intercept, modeled by the term 1, that represents the overall mean waist circumference across all nurses.\n(1 | Nurse): This specifies the random effect for Nurse, representing nurse-specific deviations from the overall mean.\n\n\n\n\nWhen you run summary(model_random), the output will display:\n\nFixed Effects: Estimates of the fixed effects\n\nIntercept: The overall mean waist circumference across all nurses.\n\nRandom Effects: Estimates of the two variance components\n\nNurse - Intercept: Between-nurse variability (\\(\\sigma^2_{b}\\)).\nResidual: Residual variance (\\(\\sigma^2\\)).\n\n\n\n\n\n\n\n\nNo p-values\n\n\n\nThe lme4 package does not provide p-values for fixed effect estimates. This is a deliberate choice by the package authors, based on concerns about the appropriateness of traditional hypothesis testing methods in the context of mixed effects models. In subsequent labs, we will use of the lmerTest package to calculate these p-values and add them to the summary output.\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nWhat proportion of the total variance is attributable to nurse differences (i.e., what is the value of the ICC)?\n\n\n\n\n\nIn mixed-effects models, model diagnostics involve analyzing different types of residuals to evaluate how well the model fits the data and to assess whether key assumptions are satisfied.\nThe default type of residuals used in these models are the conditional residuals, which are calculated based on predicted values that incorporate both fixed effects and estimated random effects. Conditional residuals represent the deviation of the observed data from the model’s predictions, accounting for variability from both sources: fixed effects and random effects. They can be considered estimates of the errors \\(\\epsilon_{ij}\\), which are assumed to be normally distributed with a mean of zero and constant variance.\nTo check these assumptions, we can generate diagnostic plots similar to those used in linear regression models:\n\nResiduals vs. Fitted Plot: This plot helps check for homoscedasticity (constant variance).\nNormal Q-Q Plot: This plot assesses whether the residuals follow a normal distribution.\n\n\n# Extract conditional residuals and predicted values\nresiduals_model_random &lt;- resid(model_random)\nfitted_model_random &lt;- fitted(model_random)\n\n# Residuals vs Fitted\nggplot(data.frame(Fitted = fitted_model_random, Residuals = residuals_model_random), aes(x = Fitted, y = Residuals)) +\n  geom_point() +\n  geom_hline(yintercept = 0, linetype = \"dashed\") +\n  labs(title = \"Residuals vs Fitted\",\n       x = \"Fitted Values\", y = \"Residuals\") +\n  theme_minimal()\n\n\n\n# Normal Q-Q\nqqnorm(residuals_model_random, main = \"Normal Q-Q\")\nqqline(residuals_model_random)\n\n\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nDo the diagnostic plots suggest any violations of the model assumptions regarding the error term?"
  },
  {
    "objectID": "Beyond MLR/BLR_lab2.html#reporting",
    "href": "Beyond MLR/BLR_lab2.html#reporting",
    "title": "Beyond Linear Regression Lab 2: Random Effects Model for the One-Way Layout",
    "section": "",
    "text": "A random effects model was fitted to assess the variability in waist circumference measurements across nurses. The overall mean waist circumference was estimated at 79.21 cm. The variance due to differences among nurses was 2.36 cm² and the residual variance was 9.73 cm², resulting in an Intraclass Correlation Coefficient (ICC) of 0.195."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Beyond MLR/BLR_lab1.html",
    "href": "Beyond MLR/BLR_lab1.html",
    "title": "Beyond Linear Regression Lab 1: Fixed Effects Model for the One-Way Layout",
    "section": "",
    "text": "In this lab, we will examine the effect of three different drug treatments (Control, Drug A, and Drug B) on blood pressure reduction in patients. The data for this example are hypothetical and will be created through simulation:\n\n# Generating data for the single-factor experimental design\nset.seed(123)\ncontrol &lt;- rnorm(40, mean = 2, sd = 10)\ndrugA &lt;- rnorm(40, mean = 20, sd = 10)\ndrugB &lt;- rnorm(40, mean = 5, sd = 10)\n\n# Combining data into a data frame\ndata_oneway &lt;- data.frame(\n  Treatment = factor(rep(c(\"Control\", \"DrugA\", \"DrugB\"), each = 40),\n                     levels = c(\"Control\", \"DrugA\", \"DrugB\")),\n  BP_Reduction = c(control, drugA, drugB)\n)\n\nThe above R chunk simulates hypothetical results for 120 parients (40 per treatment group) and stores the results in the data frame data_oneway that consists of the following two columns:\n\nTreatment: Factor variable indicating the treatment group.\nBP_Reduction: Numeric variable representing blood pressure reduction (in mm Hg).\n\n\n\nTo understand the distribution of blood pressure reduction across treatment groups, we start by creating a boxplot:\n\n# Visualizing the results\nlibrary(ggplot2)\nggplot(data_oneway, aes(x = Treatment, y = BP_Reduction, fill = Treatment)) +\n  geom_boxplot() +\n  labs(title = \"Blood Pressure Reduction by Treatment\",\n       x = \"Treatment\", y = \"Blood Pressure Reduction (mm Hg)\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\n\n\n\nWe also calculate some summary statistics:\n\n# Summarizing data\nlibrary(dplyr)\nsummary_stats &lt;- data_oneway %&gt;%\n  group_by(Treatment) %&gt;%\n  summarise(\n    Mean_BP_Reduction = mean(BP_Reduction),\n    SD_BP_Reduction = sd(BP_Reduction)\n  )\n\nsummary_stats\n\n# A tibble: 3 × 3\n  Treatment Mean_BP_Reduction SD_BP_Reduction\n  &lt;fct&gt;                 &lt;dbl&gt;           &lt;dbl&gt;\n1 Control                2.45            8.98\n2 DrugA                 19.9             9.60\n3 DrugB                  5.08            8.44\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nHow do the mean blood pressure reductions compare among the treatment groups?\n\n\n\n\n\n\n\nUsing effects coding (see @nte-codings), the one-way Analysis of Variance (ANOVA) model can be specified as:\n\\[\nY_{ij} = \\mu + \\tau_i + \\epsilon_{ij}\n\\]\nwhere:\n\n\\(Y_{ij}\\): The blood pressure reduction for the \\(j\\)-th patient in the \\(i\\)-th treatment group.\n\\(\\mu\\): The overall mean blood pressure reduction.\n\\(\\tau_i\\): The effect of the \\(i\\)-th treatment (deviation from the overall mean).\n\\(\\epsilon_{ij}\\): The error term, assumed to be independently and normally distributed with mean zero and constant variance.\n\n\n\n\n\n\n\nUnderstanding Coding Schemes\n\n\n\n\n\nIn regression models, categorical variables are represented using coding schemes. Two common coding schemes are:\n\n\n\n\n\nCompares each level of the factor to a reference level.\nIn R, this is the default coding scheme.\nThe first category is used as the reference level (unless specified otherwise).\nThe intercept represents the mean of the reference group.\nCoefficients represent differences from the reference group.\n\n\n\n\n\n\n\nLevel\nDummy Variable for B\nDummy Variable for C\n\n\n\n\nA\n0\n0\n\n\nB\n1\n0\n\n\nC\n0\n1\n\n\n\n\nInterpretation:\n\nIntercept: Mean of the reference group (A).\nCoefficient for B: Difference between mean of group A and group B.\nCoefficient for C: Difference between mean of group A and group C.\n\n\n\n\n\n\n\n\n\nCompares each level of the factor to the overall mean.\nThe sum of the coefficients equals zero.\nThe intercept represents the overall mean.\nCoefficients represent deviations from the overall mean.\n\n\n\n\n\n\n\nLevel\nEffects Code for A\nEffects Code for B\n\n\n\n\nA\n1\n0\n\n\nB\n0\n1\n\n\nC\n-1\n-1\n\n\n\n\nInterpretation:\n\nIntercept: Overall mean of all groups.\nCoefficient for A: Deviation of group A’s mean from the overall mean.\nCoefficient for B: Deviation of group B’s mean from the overall mean.\nCoefficient for C: Can be calculated as \\(-(\\beta_{\\text{A}} + \\beta_{\\text{B}})\\) since the sum of coefficients is zero.\n\n\n\n\n\n\nTo change the coding scheme globally to effects coding:\n\n# Set contrasts to effects coding globally\noptions(contrasts = c(\"contr.sum\", \"contr.poly\"))  # Effects coding\n\nTo reset the coding scheme to the default dummy coding:\n\n# Reset contrasts to default dummy coding\noptions(contrasts = c(\"contr.treatment\", \"contr.poly\"))  # Dummy coding\n\n\n\n\n\n\n\n\nWe can fit the one-way ANOVA model using the lm() function:\n\noptions(contrasts = c(\"contr.sum\", \"contr.poly\"))  # Effects coding\n\n# Fitting the model with effects coding\nmodel_oneway &lt;- lm(BP_Reduction ~ Treatment, data = data_oneway)\nsummary(model_oneway)\n\n\nCall:\nlm(formula = BP_Reduction ~ Treatment, data = data_oneway)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-23.0245  -6.0627  -0.4452   5.5324  21.7948 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   9.1544     0.8232  11.121  &lt; 2e-16 ***\nTreatment1   -6.7026     1.1642  -5.757 7.01e-08 ***\nTreatment2   10.7784     1.1642   9.258 1.22e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.018 on 117 degrees of freedom\nMultiple R-squared:  0.4276,    Adjusted R-squared:  0.4179 \nF-statistic: 43.71 on 2 and 117 DF,  p-value: 6.666e-15\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nHow do the estimated coefficients relate to the group means?\n\n\n\n\n\nTo test whether the effect of treatment is statistically significant, we use the anova() function to obtain the ANOVA table:\n\n# ANOVA table\nanova_results &lt;- anova(model_oneway)\nanova_results\n\nAnalysis of Variance Table\n\nResponse: BP_Reduction\n           Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nTreatment   2 7108.5  3554.2  43.707 6.666e-15 ***\nResiduals 117 9514.3    81.3                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nWhat does the F-test tell us about the treatment effect?\n\n\n\n\n\nEstimated marginal means, also known as least-squares means, are model-based means that represent the predicted (or expected) response at each level of a factor, averaged over the levels of other variables in the model.\nIn the context of a one-way ANOVA, where there is only one factor (e.g., treatment group), the estimated marginal means are equal to the observed group means. In more complex models with multiple factors, estimated marginal means provide predicted group means that are averaged over the levels of these additional factors. For example, in a model with both treatment and age as factors, the estimated marginal means for the treatment groups show the treatment means averaged over age, illustrating what these group means are expected to be at specific values of age (or averaged over a grid of age values).\nWe can calculate the estimated marginal means using the emmeans() function from the emmeans package:\n\n# Obtain estimated marginal means\nlibrary(emmeans)\nemms &lt;- emmeans(model_oneway, ~ Treatment)\nemms\n\n Treatment emmean   SE  df lower.CL upper.CL\n Control     2.45 1.43 117   -0.372     5.28\n DrugA      19.93 1.43 117   17.109    22.76\n DrugB       5.08 1.43 117    2.255     7.90\n\nConfidence level used: 0.95 \n\n\n\n\n\n\n\n\nQuestion\n\n\n\nHow do the estimated marginal means compare to the observed group means calculated during the exploratory data analysis?\n\n\n\n\n\nSince we found a significant treatment effect, we will conduct pairwise comparisons of the estimated marginal means to identify which specific treatment groups differ significantly from one another. We perform these pairwise comparisons using the contrast() function from the emmeans package. To account for the increased risk of Type I error due to multiple comparisons, we apply the Bonferroni correction to adjust the p-values, ensuring that the overall significance level remains controlled.\n\n# Performing post-hoc analysis with emmeans\ncontrast(emms, method=\"pairwise\", adjust=\"Bonferroni\")\n\n contrast        estimate   SE  df t.ratio p.value\n Control - DrugA   -17.48 2.02 117  -8.669  &lt;.0001\n Control - DrugB    -2.63 2.02 117  -1.303  0.5857\n DrugA - DrugB      14.85 2.02 117   7.367  &lt;.0001\n\nP value adjustment: bonferroni method for 3 tests \n\n\n\n\n\n\n\n\nQuestion\n\n\n\nBased on the results of the pairwise comparisons, which treatment groups differ significantly?\n\n\n\n\n\nTo assess the adequacy of the fitted model, we create two diagnostic plots:\n\nResiduals vs Fitted Plot: Used to assess homoscedasticity (constant variance) for the errors. A random scatter of residuals around zero indicates equal variance.\nNormal Q-Q Plot: Used to assess normality of the errors. Residuals following the reference line suggest normally distributed errors.\n\n\n# Residuals vs Fitted\nplot(model_oneway, which = 1, main = \"Residuals vs Fitted\")\n\n\n\n# Normal Q-Q\nplot(model_oneway, which = 2, main = \"Normal Q-Q\")\n\n\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nDo the diagnostic plots suggest any violations of the model assumptions?\n\n\n\n\n\n\nA one-way ANOVA was conducted to compare the effect of three treatments on blood pressure reduction. There was a statistically significant effect of treatment on blood pressure reduction [F(2, 117) = 43.71, p &lt; 0.001]. Estimated marginal means indicated that Drug A (M = 19.93 mm Hg, 95% CI = [17.11 mm Hg, 22.76 mm Hg]) resulted in significantly greater blood pressure reduction than both the Control group (M = 2.45 mm Hg, 95% CI = [-0.37 mm Hg, 5.28 mm Hg], p &lt; 0.001) and Drug B (M = 5.08 mm Hg, 95% CI = [2.26 mm Hg, 7.90 mm Hg], p &lt; 0.001). There was no significant difference between the Control group and Drug B (p = 0.586). P-values were adjusted for multiple testing using the Bonferroni correction."
  },
  {
    "objectID": "Beyond MLR/BLR_lab1.html#exploratory-data-analysis",
    "href": "Beyond MLR/BLR_lab1.html#exploratory-data-analysis",
    "title": "Beyond Linear Regression Lab 1: Fixed Effects Model for the One-Way Layout",
    "section": "",
    "text": "To understand the distribution of blood pressure reduction across treatment groups, we start by creating a boxplot:\n\n# Visualizing the results\nlibrary(ggplot2)\nggplot(data_oneway, aes(x = Treatment, y = BP_Reduction, fill = Treatment)) +\n  geom_boxplot() +\n  labs(title = \"Blood Pressure Reduction by Treatment\",\n       x = \"Treatment\", y = \"Blood Pressure Reduction (mm Hg)\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\n\n\n\nWe also calculate some summary statistics:\n\n# Summarizing data\nlibrary(dplyr)\nsummary_stats &lt;- data_oneway %&gt;%\n  group_by(Treatment) %&gt;%\n  summarise(\n    Mean_BP_Reduction = mean(BP_Reduction),\n    SD_BP_Reduction = sd(BP_Reduction)\n  )\n\nsummary_stats\n\n# A tibble: 3 × 3\n  Treatment Mean_BP_Reduction SD_BP_Reduction\n  &lt;fct&gt;                 &lt;dbl&gt;           &lt;dbl&gt;\n1 Control                2.45            8.98\n2 DrugA                 19.9             9.60\n3 DrugB                  5.08            8.44\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nHow do the mean blood pressure reductions compare among the treatment groups?"
  },
  {
    "objectID": "Beyond MLR/BLR_lab1.html#performing-a-one-way-anova",
    "href": "Beyond MLR/BLR_lab1.html#performing-a-one-way-anova",
    "title": "Beyond Linear Regression Lab 1: Fixed Effects Model for the One-Way Layout",
    "section": "",
    "text": "Using effects coding (see @nte-codings), the one-way Analysis of Variance (ANOVA) model can be specified as:\n\\[\nY_{ij} = \\mu + \\tau_i + \\epsilon_{ij}\n\\]\nwhere:\n\n\\(Y_{ij}\\): The blood pressure reduction for the \\(j\\)-th patient in the \\(i\\)-th treatment group.\n\\(\\mu\\): The overall mean blood pressure reduction.\n\\(\\tau_i\\): The effect of the \\(i\\)-th treatment (deviation from the overall mean).\n\\(\\epsilon_{ij}\\): The error term, assumed to be independently and normally distributed with mean zero and constant variance.\n\n\n\n\n\n\n\nUnderstanding Coding Schemes\n\n\n\n\n\nIn regression models, categorical variables are represented using coding schemes. Two common coding schemes are:\n\n\n\n\n\nCompares each level of the factor to a reference level.\nIn R, this is the default coding scheme.\nThe first category is used as the reference level (unless specified otherwise).\nThe intercept represents the mean of the reference group.\nCoefficients represent differences from the reference group.\n\n\n\n\n\n\n\nLevel\nDummy Variable for B\nDummy Variable for C\n\n\n\n\nA\n0\n0\n\n\nB\n1\n0\n\n\nC\n0\n1\n\n\n\n\nInterpretation:\n\nIntercept: Mean of the reference group (A).\nCoefficient for B: Difference between mean of group A and group B.\nCoefficient for C: Difference between mean of group A and group C.\n\n\n\n\n\n\n\n\n\nCompares each level of the factor to the overall mean.\nThe sum of the coefficients equals zero.\nThe intercept represents the overall mean.\nCoefficients represent deviations from the overall mean.\n\n\n\n\n\n\n\nLevel\nEffects Code for A\nEffects Code for B\n\n\n\n\nA\n1\n0\n\n\nB\n0\n1\n\n\nC\n-1\n-1\n\n\n\n\nInterpretation:\n\nIntercept: Overall mean of all groups.\nCoefficient for A: Deviation of group A’s mean from the overall mean.\nCoefficient for B: Deviation of group B’s mean from the overall mean.\nCoefficient for C: Can be calculated as \\(-(\\beta_{\\text{A}} + \\beta_{\\text{B}})\\) since the sum of coefficients is zero.\n\n\n\n\n\n\nTo change the coding scheme globally to effects coding:\n\n# Set contrasts to effects coding globally\noptions(contrasts = c(\"contr.sum\", \"contr.poly\"))  # Effects coding\n\nTo reset the coding scheme to the default dummy coding:\n\n# Reset contrasts to default dummy coding\noptions(contrasts = c(\"contr.treatment\", \"contr.poly\"))  # Dummy coding\n\n\n\n\n\n\n\n\nWe can fit the one-way ANOVA model using the lm() function:\n\noptions(contrasts = c(\"contr.sum\", \"contr.poly\"))  # Effects coding\n\n# Fitting the model with effects coding\nmodel_oneway &lt;- lm(BP_Reduction ~ Treatment, data = data_oneway)\nsummary(model_oneway)\n\n\nCall:\nlm(formula = BP_Reduction ~ Treatment, data = data_oneway)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-23.0245  -6.0627  -0.4452   5.5324  21.7948 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   9.1544     0.8232  11.121  &lt; 2e-16 ***\nTreatment1   -6.7026     1.1642  -5.757 7.01e-08 ***\nTreatment2   10.7784     1.1642   9.258 1.22e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.018 on 117 degrees of freedom\nMultiple R-squared:  0.4276,    Adjusted R-squared:  0.4179 \nF-statistic: 43.71 on 2 and 117 DF,  p-value: 6.666e-15\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nHow do the estimated coefficients relate to the group means?\n\n\n\n\n\nTo test whether the effect of treatment is statistically significant, we use the anova() function to obtain the ANOVA table:\n\n# ANOVA table\nanova_results &lt;- anova(model_oneway)\nanova_results\n\nAnalysis of Variance Table\n\nResponse: BP_Reduction\n           Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nTreatment   2 7108.5  3554.2  43.707 6.666e-15 ***\nResiduals 117 9514.3    81.3                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nWhat does the F-test tell us about the treatment effect?\n\n\n\n\n\nEstimated marginal means, also known as least-squares means, are model-based means that represent the predicted (or expected) response at each level of a factor, averaged over the levels of other variables in the model.\nIn the context of a one-way ANOVA, where there is only one factor (e.g., treatment group), the estimated marginal means are equal to the observed group means. In more complex models with multiple factors, estimated marginal means provide predicted group means that are averaged over the levels of these additional factors. For example, in a model with both treatment and age as factors, the estimated marginal means for the treatment groups show the treatment means averaged over age, illustrating what these group means are expected to be at specific values of age (or averaged over a grid of age values).\nWe can calculate the estimated marginal means using the emmeans() function from the emmeans package:\n\n# Obtain estimated marginal means\nlibrary(emmeans)\nemms &lt;- emmeans(model_oneway, ~ Treatment)\nemms\n\n Treatment emmean   SE  df lower.CL upper.CL\n Control     2.45 1.43 117   -0.372     5.28\n DrugA      19.93 1.43 117   17.109    22.76\n DrugB       5.08 1.43 117    2.255     7.90\n\nConfidence level used: 0.95 \n\n\n\n\n\n\n\n\nQuestion\n\n\n\nHow do the estimated marginal means compare to the observed group means calculated during the exploratory data analysis?\n\n\n\n\n\nSince we found a significant treatment effect, we will conduct pairwise comparisons of the estimated marginal means to identify which specific treatment groups differ significantly from one another. We perform these pairwise comparisons using the contrast() function from the emmeans package. To account for the increased risk of Type I error due to multiple comparisons, we apply the Bonferroni correction to adjust the p-values, ensuring that the overall significance level remains controlled.\n\n# Performing post-hoc analysis with emmeans\ncontrast(emms, method=\"pairwise\", adjust=\"Bonferroni\")\n\n contrast        estimate   SE  df t.ratio p.value\n Control - DrugA   -17.48 2.02 117  -8.669  &lt;.0001\n Control - DrugB    -2.63 2.02 117  -1.303  0.5857\n DrugA - DrugB      14.85 2.02 117   7.367  &lt;.0001\n\nP value adjustment: bonferroni method for 3 tests \n\n\n\n\n\n\n\n\nQuestion\n\n\n\nBased on the results of the pairwise comparisons, which treatment groups differ significantly?\n\n\n\n\n\nTo assess the adequacy of the fitted model, we create two diagnostic plots:\n\nResiduals vs Fitted Plot: Used to assess homoscedasticity (constant variance) for the errors. A random scatter of residuals around zero indicates equal variance.\nNormal Q-Q Plot: Used to assess normality of the errors. Residuals following the reference line suggest normally distributed errors.\n\n\n# Residuals vs Fitted\nplot(model_oneway, which = 1, main = \"Residuals vs Fitted\")\n\n\n\n# Normal Q-Q\nplot(model_oneway, which = 2, main = \"Normal Q-Q\")\n\n\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nDo the diagnostic plots suggest any violations of the model assumptions?\n\n\n\n\n\n\nA one-way ANOVA was conducted to compare the effect of three treatments on blood pressure reduction. There was a statistically significant effect of treatment on blood pressure reduction [F(2, 117) = 43.71, p &lt; 0.001]. Estimated marginal means indicated that Drug A (M = 19.93 mm Hg, 95% CI = [17.11 mm Hg, 22.76 mm Hg]) resulted in significantly greater blood pressure reduction than both the Control group (M = 2.45 mm Hg, 95% CI = [-0.37 mm Hg, 5.28 mm Hg], p &lt; 0.001) and Drug B (M = 5.08 mm Hg, 95% CI = [2.26 mm Hg, 7.90 mm Hg], p &lt; 0.001). There was no significant difference between the Control group and Drug B (p = 0.586). P-values were adjusted for multiple testing using the Bonferroni correction."
  }
]